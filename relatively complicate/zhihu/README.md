# scrapy爬取知乎用户动态

## 前期准备

### 环境

- Ubuntu 18.04
- Python 3.8
- Scrapy 2.1

### 外部包

- pymysql

## 分析目标网站

### 反爬

- 知乎是一个反爬力度做的比较大的网站，全站大量采用ajax，一般通过请求页面解析的方式根本行不通。所以我们通过解析知乎的数据接口，通过请求数据接口来获取数据。

- 同时知乎还有大量的加密验证，不过好在这次我们的目标主要是用户的动态，知乎对此并未做加密处理，无需填写cookie等信息，最重要的是不用解决麻烦的xsrf验证问题。

### 思路

- 我们的目标是获取5000个用户的动态信息，第一步就是想办法找到5000个用户。初步想到两种方法：
  - 一种是在问题下爬取用户的评论、回答等信息。但是这样效率极低，而且要面对知乎复杂的xsrf验证问题，同时很容易爬取到相同的用户。好处是用户集群比较分散，爬取到的用户更具有普遍的代表性
  - 第二种是找一个知乎的大V，经过测试知乎的关注者部分的接口并未加密，我们可以很轻松的获取到大量的用户链接，同时绝无重复，实现起来效率很高，并且相对简单很多；缺点就是用户的共性较高，可能普遍的代表性比较差，但是可以通过选取一个专业性较弱，内容输出比较容易吸引普通大众的大v来爬取，粉丝的共性相对较小。
- 本次我们选用第二种方式来获取用户。有了用户链接，我们再来分析用户动态的数据接口，发现也并未加密，故我们可以轻松拿到动态数据，只需要简单去重就可以了。但有一点要注意的就是知乎存在IP检查，如果访问过于频繁，IP会被拉入黑名单，所以需要建立一个IP池，以免IP被封程序死掉。
- 最后一步存储数据，因为我们本次采用scrapy框架爬取数据，scrapy采用了并发异步爬取的方式，所以我们在存储数据的时候未了不让数据存储拖后腿，也需要采用异步存储的方式，以提高效率。
